{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suspected-weekend",
   "metadata": {},
   "source": [
    "# spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. \n",
    "## It uses object-oriented approach rather than using list of strings like nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flying-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Example sentance\n",
    "\n",
    "sent =\"Hey This is me . i am looking for you since past year . where are you now a days? how's your brother ? i am helping you .he steped out from camping . i seen many bridges . nothing can be done . rahul is honest boy . america has newyork state . elon is richest among all and he owns tesla and spacex . he studied from stanford university\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "roman-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')    # python -m spacy download en_core_web_sm\n",
    "\n",
    "doc  = nlp(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13355c8",
   "metadata": {},
   "source": [
    "## Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a20c462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey This is me .\n",
      "i am looking for you since past year .\n",
      "where are you now a days?\n",
      "how's your brother ?\n",
      "i am helping you .he\n",
      "steped out from camping .\n",
      "i seen many bridges .\n",
      "nothing can be done .\n",
      "rahul is honest boy .\n",
      "america has newyork state .\n",
      "elon is richest among all and he owns tesla and spacex .\n",
      "he studied from stanford university\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-baseline",
   "metadata": {},
   "source": [
    "## Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "approved-accident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey 0\n",
      "This 1\n",
      "is 2\n",
      "me 3\n",
      ". 4\n",
      "i 5\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.i > 5:\n",
    "        break\n",
    "    print(token.text , token.i)    # token text , token index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-lawyer",
   "metadata": {},
   "source": [
    "## POS Tagging  (part Of Speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "brown-contrary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  Hey  -  INTJ\n",
      "1  -  This  -  PRON\n",
      "2  -  is  -  AUX\n",
      "3  -  me  -  PRON\n",
      "4  -  .  -  PUNCT\n",
      "5  -  i  -  PRON\n",
      "6  -  am  -  AUX\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print( token.i , \" - \", token.text , \" - \", token.pos_)    # token text , token index\n",
    "    if token.i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-wholesale",
   "metadata": {},
   "source": [
    "ADJ: adjective, e.g. big, old, green, incomprehensible, first\n",
    "\n",
    "ADP: adposition, e.g. in, to, during\n",
    "\n",
    "ADV: adverb, e.g. very, tomorrow, down, where, there\n",
    "\n",
    "AUX: auxiliary, e.g. is, has (done), will (do), should (do)\n",
    "\n",
    "CONJ: conjunction, e.g. and, or, but\n",
    "\n",
    "CCONJ: coordinating conjunction, e.g. and, or, but\n",
    "\n",
    "DET: determiner, e.g. a, an, the\n",
    "\n",
    "INTJ: interjection, e.g. psst, ouch, bravo, hello\n",
    "\n",
    "NOUN: noun, e.g. girl, cat, tree, air, beauty\n",
    "\n",
    "NUM: numeral, e.g. 1, 2017, one, seventy-seven, IV, MMXIV\n",
    "\n",
    "PART: particle, e.g. ‚Äôs, not,\n",
    "\n",
    "PRON: pronoun, e.g I, you, he, she, myself, themselves, somebody\n",
    "\n",
    "PROPN: proper noun, e.g. Mary, John, London, NATO, HBO\n",
    "\n",
    "PUNCT: punctuation, e.g. ., (, ), ?\n",
    "\n",
    "SCONJ: subordinating conjunction, e.g. if, while, that\n",
    "\n",
    "SYM: symbol, e.g. $, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù\n",
    "\n",
    "VERB: verb, e.g. run, runs, running, eat, ate, eating\n",
    "\n",
    "X: other, e.g. sfpksdpsxmsa\n",
    "\n",
    "SPACE: space, e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-broadcast",
   "metadata": {},
   "source": [
    "## Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "homeless-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past year  -  DATE\n",
      "america  -  GPE\n",
      "stanford university  -  ORG\n"
     ]
    }
   ],
   "source": [
    "for token in doc.ents:\n",
    "    print( token.text ,\" - \", token.label_)    # token text , token index\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-walter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-spanish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-trace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-flash",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-crisis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-nightmare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-kidney",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-remains",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
