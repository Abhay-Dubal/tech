                            _              _                                    _                
                            | | __  _   _  | |__     ___   _ __   _ __     ___  | |_    ___   ___ 
                            | |/ / | | | | | '_ \   / _ \ | '__| | '_ \   / _ \ | __|  / _ \ / __|
                            |   <  | |_| | | |_) | |  __/ | |    | | | | |  __/ | |_  |  __/ \__ \
                            |_|\_\  \__,_| |_.__/   \___| |_|    |_| |_|  \___|  \__|  \___| |___/
                                                                                                

                                    _         _                 _         
                             ___   | |__     (_)   ___    ___  | |_   ___ 
                            / _ \  | '_ \    | |  / _ \  / __| | __| / __|
                           | (_) | | |_) |   | | |  __/ | (__  | |_  \__ \
                            \___/  |_.__/   _/ |  \___|  \___|  \__| |___/
                                            |__/                           


kubernetes offers following objects/components :


diff types of object available in k8s are :


					---------------------------------------------------------------------------
					|                  Pod					 	        |
					---------------------------------------------------------------------------

                    it is smalles unit of k8s, it is used to run application on k8s cluster.
                    A pod is a collection of containers and its storage inside a node of a Kubernetes cluster. 
                    It is possible to create a pod with multiple containers inside it. 


                    pod has its own ip address but containers inside pods not have their own ip address

                    evrytime pod gets created it will get new ip address only

                    if a single container inside pod fails then whole pod is discarded and new pod is creared as that pod cant be repaired or reconstructed, 
                    this is disadvatage of multi conatainer pod .
                    so , it is recommended that to use Single container

                    we can get in to pod also with using exec 

                    if pod having resource quota that has limit exceeding limits defined in limit range / service quota , pod will not created
                    same with request , if it is below the mentioned it will not created

                    Pod is running and has two Containers. Container 1 exits with failure.

                        1.Log failure event.

                        2.If restartPolicy is:

                            Always: Restart Container; Pod phase stays Running.

                            OnFailure: Restart Container; Pod phase stays Running.

                            Never: Do not restart Container; Pod phase stays Running
                                So pod is not restarted or the other container is not restarted , 
                                only the exited container is restarted based on the restartPolicy




                    --------------------   Init Containers  ---------------------------------

                    Init containers can contain utilities or setup scripts not present in an app image.

                    Pod can have multiple containers running apps within it, but it can also have one or more init containers, which are run before the app containers are started.

                    If a Pod's init container fails, the kubelet repeatedly restarts that init container until it succeeds.
                    if init succeeds then only app container will be started

                    To specify an init container for a Pod, add the initContainers field into the Pod specification, as an array of container items (similar to the app containers field and its contents). 

                    init containers do not support lifecycle, livenessProbe, readinessProbe, or startupProbe because they must run to completion before the Pod can be ready.

                    specifying multiple init containers for a Pod, kubelet will runs each init container sequentially . 
                    Each init container must succeed before the next can run.


                    ------------------------ Pod lifecycle ---------------------------------

                    Phases of a Pod =:

                    Pending	=> Pod has been accepted by the Kubernetes cluster, but is waiting for resources to be allocated.
                                This includes time a Pod spends waiting to be scheduled as well as the time spent downloading container images over the network.

                    Running	=>  Pod has been bound to a node, and all of the containers have been created. 
                                At least one container   is still running, or is in the process of starting or restarting.

                    Succeeded =>  All containers in the Pod have terminated in success, and will not be restarted.	

                    Failed	 =>  All containers in the Pod have terminated, and at least one container has terminated in failure

                    Unknown	 =>   For some reason the state of the Pod could not be obtained. 
                                    This phase typically occurs due to an error in communicating with the node 
                                    where the Pod should be running.

                    Terminating status is not one of the Pod phases. A Pod is granted a term to terminate gracefully, which defaults to 30 seconds.

                    init:N/M means the Pod has M Init Containers, and N have completed so far.

                    ------------------------ Pod Conditions ---------------------------------

                    all of the following has boolean value true or false , we can get this using describe

                    PodScheduled =: the Pod has been scheduled to a node.

                    ContainersReady =: all containers in the Pod are ready.

                    Initialized =: all init containers have completed successfully.

                    Ready =: the Pod is able to serve requests and 
                                should be added to the load balancing pools of all matching Services.

					---------------------------------------------------------------------------
					|                                    Services				         	 |
					---------------------------------------------------------------------------

                    services are attached to pods , even if pod dies , services remain as it is and can be attched to new pod 

                    each service has its own ip address and port number

                    so that they are used in crusial container application like database so that even the db pod get terminated , 
                    data and connection to db by other services will never get lost

                    there are 2 types of services available in k8s:

                            1. Internal services : 

                                        used in pods that not need to expose to world like database , only require to be used by other pods

                            2. External services :

                                        used in pods that need to be exposed to world like web server 

                    there are 3 types available in service :

                        1. ClusterIP   :    Default , accessible only within cluster (cluster can contains multiple nodes)

                        2. NodePort    :     can be accessible static port on each node , this static port in defined in .spec.ports.nodePort
                                                static port should be between 30000 - 32767 , other than that not accepted
                                                not secure and not efficient , used only for test


                        3. LoadBalancer :   

                        4. Headless :   



                    ClusterIP < Nodeport < LoadBalancer 


               		---------------------------------------------------------------------------
					|                                         Ingress 	        				 |
					---------------------------------------------------------------------------


                    it is type of External service that is used to expose services to the world but using a secure protol like https and with domain name

                    if request comes to the domain name , it will be routed to the service by ingress

                    it is used in real world applications not the LoadBalancer



           			 ---------------------------------------------------------------------------
					|                               configmap               				 |
					---------------------------------------------------------------------------

                    In programming, we use env files or separate configuration files to store settings, configurations, or variables that are required to execute the program. 
                    In Kubernetes, we can use ConfigMaps to achieve the same functionality.
		            A ConfigMap is a Kubernetes API object that can be used to store data as key-value pairs. Kubernetes pods can use the created ConfigMaps as a:

                                    Configuration file
                                    Environment variable
                                    Command-line argument

		            ConfigMaps provides the ability to make applications portable by decoupling environment-specific configurations from the containers.

                    * Importantly, ConfigMaps are not suitable for storing confidential data. They do not provide any kind of encryption, and all the data in them are
                            visible to anyone who has access to the file. (Kubernetes provides secrets that can be used to store sensitive information.)





                    ---------------------------------------------------------------------------
					|                                 secreats			        	   	 |
					---------------------------------------------------------------------------

                    Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key. 
                    Such information might otherwise be put in a Pod specification or in a container image. 
                    Using a Secret means that you don't need to include confidential data in your application code.

                    Because Secrets can be created independently of the Pods that use them, 
                    there is less risk of the Secret (and its data) being exposed during the workflow of creating, 
                    viewing, and editing Pods. Kubernetes, and applications that run in your cluster, can also take additional precautions with Secrets, 
                    such as avoiding writing confidential data to nonvolatile storage.

                    Secrets are similar to ConfigMaps but are specifically intended to hold confidential data.
                    it is stored in etcd with base64 encoding , now we can encrypt it using KMS 
                        so that only using application specific keys we can access the data 



                    ---------------------------------------------------------------------------
					|                           Volume      				 				 |
					---------------------------------------------------------------------------

                    Volume is a container for a file or directory on the host machine that is mounted into a container. it is user managed
                    it can be on cloud also. like awsElasticBlockStore volume mounts an Amazon Web Services (AWS) EBS volume into your pod
                    concept of volume was present with the Docker, however the only issue was that the volume was very much limited to a particular pod.
                     As soon as the life of a pod ended, the volume was also lost.


                     Pod can use any number of volume types simultaneously. 
                     Ephemeral volume types have a lifetime of a pod, but persistent volumes exist beyond the lifetime of a pod. 
                     When a pod ceases to exist, Kubernetes destroys ephemeral volumes; however, Kubernetes does not destroy persistent volumes. 
                     For any kind of volume in a given pod, data is preserved across container restarts.


                    Types of Volumes in Kubernetes :


                            Persistent Volumes  :  A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by 
                                                   an administrator or dynamically provisioned using Storage Classes. 
                                                   PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. 

                                            e.g. hostpath  , here both pod and host can write and read data

                                            apiVersion: v1
                                            kind: Pod
                                            metadata:
                                            name: myvolhostpath
                                            spec:
                                            containers:
                                            - image: centos
                                                name: testc
                                                command: ["/bin/bash", "-c", "sleep 15000"]
                                                volumeMounts:
                                                - mountPath: /tmp/hostpath
                                                name: testvolume
                                            volumes:
                                            - name: testvolume
                                                hostPath:
                                                path: /tmp/data   # at this location of host machine 

                            Projected Volumes   :  A projected volume maps several existing volume sources into the same directory.
                                                    Currently, the following types of volume sources can be projected:
                                                                secret
                                                                downwardAPI
                                                                configMap
                                                                serviceAccountToken


                            Ephemeral Volumes   :  volumes follow the Pod's lifetime and get created and deleted along with the Pod

                                        e.g.  = emptydir  , here in a single pod we can share same volume among different containers

                                          - name: c1
                                            image: centos
                                            command: ["/bin/bash", "-c", "sleep 15000"]
                                            volumeMounts:                                    
                                            - name: xchange
                                                mountPath: "/tmp/xchange"               # avilable in this path 
                                         - name: c2
                                            image: centos
                                            command: ["/bin/bash", "-c", "sleep 10000"]
                                            volumeMounts:
                                            - name: xchange
                                                mountPath: "/tmp/data"
                                         - name: xchange
                                            emptyDir: {}



			    	---------------------------------------------------------------------------
					|                            ReplicationController		     			 |
					---------------------------------------------------------------------------

                    Replication Controller is one of the key features of Kubernetes, which is responsible for managing the pod lifecycle. 
                    It is responsible for making sure that the specified number of pod replicas are running at any point of time. 
                    It is used in time when one wants to make sure that the specified number of pod or at least one pod is running. 
                    It has the capability to bring up or down the specified no of pod.



                   	--------------------------------------------------------------------------
					|                                    ReplicaSet  						 |
					---------------------------------------------------------------------------
                      --- advanced version of ReplicationController , it support equality as well as set based selectors

                                A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time. 
                                As such, it is often used to guarantee the availability of a specified number of identical Pods.


					---------------------------------------------------------------------------
					|                         Deployment   			                		 |
					---------------------------------------------------------------------------


                    more powerful than replicaset  , it can manage multiple replicaset
	                we can do updates and rollbacks using deployment but it is not possible in case of replicaset
					it deploys pods using replicaset only
                    it is abstraction on replica set that is abstraction on pod that is abstraction on container

                    A Deployment provides declarative updates for Pods and ReplicaSets.

                    Naming in deployment :

                            Deployment : mydeploy

                            replicaset(rs) : mydeploy-rs_id

                            pods : mydeploy-rs_id-pod_id


                    Create a Deployment to rollout a ReplicaSet. The ReplicaSet creates Pods in the background. Check the status of the rollout to see if it succeeds or not.

                    Declare the new state of the Pods by updating the PodTemplateSpec of the Deployment. 
                    A new ReplicaSet is created and the Deployment manages moving the Pods from the old ReplicaSet to the new one at a controlled rate. 
                    Each new ReplicaSet updates the revision of the Deployment.

                    Rollback to an earlier Deployment revision if the current state of the Deployment is not stable. Each rollback updates the revision of the Deployment.

                    Scale up the Deployment to facilitate more load.

                    Pause the rollout of a Deployment to apply multiple fixes to its PodTemplateSpec and then resume it to start a new rollout.

                    Use the status of the Deployment as an indicator that a rollout has stuck.

                    Clean up older ReplicaSets that you don't need anymore.

                    Everytime when deploy named <deployment-name> is updated or runned , it will create version for that and using rollout we can rollback 
                    to any version of that deployment



                    In order to rollout back to previous specific version we use :

                            kubectl rollout status deployment <deployment-name>

                            kubctl rollout undo deployment <deployment-name> --to-revision=<revision-number>          -- get rivision number using history commnd

                    To see the rollout history of a deployment we use :

                            kubectl rollout history deployment <deployment-name>


                    To change scale of deployments use :

                            kubectl scale --replicas=<number-of-replicas> deployment <deployment-name> 


                    After changing some of the deployment parameters and after applying again will lead to create new replicaset 
                    previous replicaset will remain as it is , only pods inside that will be terminated 
                    new pods will be created inside the new replicaset and no. of pods will be equal to number of replicas specified in deployment


                    Deploy ment may fails due to Following reasons :

                    1. insufficient quota on nodes to deploy new pods
                    2. Readiness probe failure   -> occures when node is not ready to serve new pods 
                    3. Image pull Error : mentoined container image is not available or it is not in local registry and imagePullPolicy is set to never
                    4. insufficient Permissions
                    5. Limit Ranges : when node reaches its limit 

					---------------------------------------------------------------------------
					|                      StatefulSets     				 |
					---------------------------------------------------------------------------

                    there will be data inconsistancy if 2 or more pods performing same operation at same/different time cauing data loss/error 
                    like transaction control in database

                    so that satefulsets are used in stateful operations like database 

                    because of that stateful sets are used to manage stateful pods not the deployments

                    it also manages replication of pods just like deployment

                    it sures that read and write in this pods are synchronized

                    it is difficult than deployments 

                    Unlike a Deployment, a StatefulSet maintains a sticky identity for each of their Pods. 
                    These pods are created from the same spec, but are not interchangeable: 
                                    each has a persistent identifier that it maintains across any rescheduling.

					---------------------------------------------------------------------------
					|                            DaemonSets					 |
					---------------------------------------------------------------------------

                    A DaemonSet ensures that all (or some) Nodes run a copy of a Pod. As nodes are added to the cluster, Pods are added to them. 
                    As nodes are removed from the cluster, those Pods are garbage collected. Deleting a DaemonSet will clean up the Pods it created.

                    Daemonset is another controller that manages pods like Deployments, ReplicaSets, and StatefulSets. It was created for one particular purpose: ensuring that the pods it manages to run on all the cluster nodes. As soon as a node joins the cluster, the DaemonSet ensures that it has the necessary pods running on it. When the node leaves the cluster, those pods are garbage collected.

                    By default, a DaemonSet schedules its pods on all the cluster nodes

                    Also DaemonSets allow you to select which nodes you want to run the pods on. 
                    With nodeSelector, you can select nodes by their labels

                    it is not possible in AWS EKS so we need to use sidecar instead of DaemonSets

                 


					---------------------------------------------------------------------------
					|                               Namespace		    	            	 |
					---------------------------------------------------------------------------

                    namespaces provides a mechanism for isolating groups of resources within a single cluster. 
                    Names of resources need to be unique within a namespace, but not across namespaces. 
                    Namespace-based scoping is applicable only for namespaced objects (e.g. Deployments, Services, etc) and 
                    not for cluster-wide objects (e.g. StorageClass, Nodes, PersistentVolumes, etc)

                    By default namespace is :  default

                    using tool kubens we change default namesapce to any names space we want

                    Resource Quoto is allocated to namespace , all the objects created in that namespace can not use exceed resource qutoa limit



                    By default resource quota is set to 0 means no limit to access resources

                    we can define resurce qutoa on   1. Ram   2. storage    3. CPU

                    here we have 2 options :
                            1. Request  => amout of resources object needed , , if not mentioned by default it is same as limit

                            2. Limit  => maximum resources object can use , if not mentioned by default it is maximum available
                    
                    we can use resurce quota imperatively as well as declaratively

                    we can use resource quota declaratively by using :

                            kubectl create quota <quota-name> --hard=<resource-name>=<value>

                            memory refers to RAM

                                    resource-name can be = 

                                          limits.<Resource-Object>=Value      e.g.  limits.cpu: "400m"

                                          requests.<Resource-Object>=Value      e.g.  requests.memory: "200Mi"
  
                                only   cpu considered	Same as requests.cpu
                    
                    The resource quota is the total available resources for a particular namespace, while limit range is used to assign limits for containers(Pods) running inside the namespace.
                    ResourceQuota is for limiting the total resource consumption of a namespace
                    LimitRangeis for managing constraints at a pod and container level within the project.
	
					---------------------------------------------------------------------------
					|                            ResourceQuota                  	 	 |
					---------------------------------------------------------------------------

                    we can define ResourceQuota using declarative method

                    The name of a ResourceQuota object must be a valid DNS subdomain name.

                    If creating or updating a resource violates a quota constraint, the request will fail with 
                    HTTP status code 403 FORBIDDEN with a message explaining the constraint that would have been violated.

                    it will applied to current namespace only , every object created in that namespace will be checked against quota

                    with resource quota we can define max pods will be created inside a namesapce

					---------------------------------------------------------------------------
					|                             Limit Range	                     	 |
					---------------------------------------------------------------------------

                    it used to set limit on object's max resource use

                    Within a namespace, a Pod or Container can consume as much CPU and memory as defined by the namespace's resource quota.

                    There is a concern that one Pod or Container could monopolize all available resources.
                     
                    A LimitRange is a policy to constrain resource allocations (to Pods or Containers) in a namespace.

                    LimitRange provides to Enforce minimum and maximum compute resources usage per Pod n a namespace.
                    Also Enforce minimum and maximum storage request per PersistentVolumeClaim in a namespace.

                    name of a LimitRange object must be a valid DNS subdomain name

                    LimitRange validations occurs only at Pod Admission stage, not on Running Pods.

                    If any container in that Pod does not specify its own CPU request and limit, the control plane assigns the default CPU request and limit to that container. i.e. which is mentioned in LimitRange Object

                    When creating a LimitRange object, you can specify limits on huge-pages or GPUs as well. However, when both default and defaultRequest are specified on these resources, the two values must be the same.

                    


					---------------------------------------------------------------------------
					|                  Persistent Volume Claim		(PVC)	 	 |
					---------------------------------------------------------------------------


                    it should be in same namespace as a pod is .  

	
					---------------------------------------------------------------------------
					|                       Storage Class		 			 |
					---------------------------------------------------------------------------
             
					---------------------------------------------------------------------------
					|                              Network policy  	        	 			 |
					---------------------------------------------------------------------------

                    it is used to restrict network access to a pod or whole namespace

                    with this , we can set policies so that only allowed namespaces traffic can come

                    to use this , we need network policy agents like Antrea 
             
	
					---------------------------------------------------------------------------
					|                                Liveness		 	        		 |
					---------------------------------------------------------------------------

                    Using liveness we can check if the service inside pod is running properly or not.
                    

					---------------------------------------------------------------------------
					|                                   Job     		 	        		 |
					---------------------------------------------------------------------------

                    performs batch operations

                    like for log opearations we need to terminate pod after successful completion of log operations
                    Kubernetes Jobs ensure that one or more pods execute their commands and exit successfully.

                    When all the pods have exited without errors, the Job gets completed. When the Job gets deleted, any created pods get deleted as well.

                    Pods gets deleted after successful ecxecution of job , but job remains , we need to delete manually 

                    lifecycle:
                        1. job is created
                        2. pods are created according to job spec
                        3. containers inside pod perform operation that are mentioned.
                        4. when all containers are done , pod gets terminated, job is completed

    
     
    DeploymentController (Manages Pods)
	
	  ----- 

You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate.
 You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.


Other Objects ;

Custom Resource Definition (CRD) : used for custom controller

    
    
