******************************************************************************************************************************************************************************************
										About Kubernetes
******************************************************************************************************************************************************************************************

* imperative means use cli every time to execute , declarative means make file and then execute it every time 

simply container management/orchestration tool , also known as k8s , Container orchestration automates the deployment, management, scaling, and networking of containers.
orchestration means clustering of any no of containers running on any network , it can works on also hybrid cloud also
Kubernetes was originally developed and designed by engineers at Google. it was developed in Golang , it supports menifest scripts in JSON and Yaml

container orchestration to automate and manage tasks such as:

	Provisioning and deployment
	Configuration and scheduling 
	Resource allocation
	Container availability 
	Scaling or removing containers based on balancing workloads across your infrastructure (can scale vertically[amount of resources] as well horizontally[no of containers])
	Load balancing and traffic routing 
	Monitoring container health
	Configuring applications based on the container in which they will run
	Keeping interactions between containers secure
	batch execution (manifest are used like recipe)

it is  Container as a Service (CaaS) . CaaS is cloud service that allows software developers and IT departments to upload, organize, run, scale, manage and stop containers by using 	container-based virtualization

Alternatives:
	AWS Fargate.
	Azure Container Instances. 
	Google Cloud Run.
	Google Kubernetes Engine (GKE) 
	Amazon Elastic Kubernetes Service (EKS) 
	Openshift Container Platform. 
	Rancher. 
	Docker Swarm.
	Apache marathon 


Kubernetes comparison with its top compatitor docker swarm :

	it has gui but swarm does not have
	it is complex and harder than swarm but it has more features than swarm
	data sharabilty is only within pod in case of kubernetes but in swarm it is sharable throughout all containers
	swarm only supports only while k8s supports  Docker, containerd, CRI-O, and any implementation of the Kubernetes CRI 
	it has support of auto scaling in both direction but swarm does not have
	k8s has its own monitering tool but swarm needs 3rd party tool to perform this


Architecture :

	it has master- node architecture inside a cluter , node is pod which can have 1 or more worker containers runnign in it , containers communicates with pods , diff pods can have diff types of container services running in it , like in 1 pod 20 docker containers are running but in 2 nd pod from same cluster can have 30 OpenVZ or containerd conatiners running at same time 
	containers run microservice 


								  ------Cluster----------
								  |			 |
								master 			node ---------------------------- (it can have multiple nodes for multiple purpoes)
											|                |               |
											pod1 		pod2    	pod3 (generally all pods runs same application from same node)
											  | 		  |		  |		
											cont1		cont1		cont1 (diff types of container services can be used )
											cont2


	Kubernetes - Master Machine Components


	
			# Controller Manager
					This component is responsible for most of the collectors that regulates the state of cluster and performs a task. In general, it can be considered as 					a daemon which runs in nonterminating loop and is responsible for collecting and sending information to API server. It works toward getting the 					shared state of cluster and then make changes to bring the "current status" of the server to "desired state".The controller manager runs different 						kind of controllers to handle nodes, endpoints, etc.

			# etcd
					It stores the configuration information which can be used by each of the nodes in the cluster. It is a high availability key value store that can be 					distributed among multiple nodes. It is accessible only by Kubernetes API server as it may have some sensitive information. It is a distributed key 					value Store which is accessible to all.

			
			# Scheduler
					This is one of the key components of Kubernetes master. It is a service in master responsible for distributing the workload. It is responsible for 					tracking utilization of working load on cluster nodes and then placing the workload on which resources are available and accept the workload.The 					scheduler is responsible for workload utilization and allocating pod to new node.

	
			# API Server
					Kubernetes is an API server which provides all the operation on cluster using the API. API server implements an interface, which means different 					tools and libraries can readily communicate with it. Kubeconfig is a package along with the server side tools that can be used for communication. It 					exposes Kubernetes API.

A minimum Kubernetes master node configuration is:
	4 CPU cores (Intel VT-capable CPU)
	16GB RAM.
	1GB Ethernet NIC.
	40GB hard disk space in the /var directory.

On AWS
	sizes we use on AWS are(master requirements)

		1-5 nodes: m3.medium
		6-10 nodes: m3.large
		11-100 nodes: m3.xlarge
		101-250 nodes: m3.2xlarge
		251-500 nodes: c4.4xlarge
		more than 500 nodes: c4.8xlarge

				Master									Node


					it has all data of nodes 			    sends data
						ETCD (can be accessed only by apiserver)   <------     Kubelet(each for every node)
					         ^						  / --- Node 1  ---  pod11  -> cont1 , cont2
it checks etcd via server and commands           |						/
	 sheduler to perform actions		 |                                            /				  
		CONTROL MANAGER	-------->   API SERVER ----------------------------------------  ------- Node2  ----pod21  -> cont1 
						|							   |
						|							    -------- pod22  -> 	cont1 , cont2 , cont3			
						SCHEDULER (actions taken here actually)	
	

		* Admin sends menifest to Api server then control manager check actual and desired state with help of etcd and commands scheduler to perform necessory action to get in 			desired state , menifest scripts written in JSON OR Yaml contains



	Kubernetes - Node Components


			# Kubelet Service (sends node status to etcd) 10225 port by default

					This is a small service in each node responsible for relaying information to and from control plane service. It interacts with etcd store to read 					configuration details and wright values. This communicates with the master component to receive commands and work. The kubelet process then assumes 					responsibility for maintaining the state of work and the node server. It manages network rules, port forwarding, etc.


			# Kubernetes Proxy Service (each pod has ip to communicate with other pods or external network )

					This is a proxy service which runs on each node and helps in making services available to the external host. It helps in forwarding the request to 					correct containers and is capable of performing primitive load balancing. It makes sure that the networking environment is predictable and accessible 					and at the same time it is isolated as well. It manages pods on node, volumes, secrets, creating new containers’ health checkup, etc.

		
			# Container Engine (e.g, Docker)

					The first requirement of each node is Docker which helps in running the encapsulated application containers in a relatively isolated but lightweight 					operating environment.




		///  ***  POD    ***  ////

A pod is a collection of containers and its storage inside a node of a Kubernetes cluster. It is possible to create a pod with multiple containers inside it. For example, keeping a database container and data container in the same pod.

Types of Pod
	There are two types of Pods −

		Single container pod - 
				They can be simply created with the kubctl run command, where you have a defined image on the Docker registry which we will pull while creating a pod.
			
		Multi container pod - 
				Multi container pods are created using yaml mail with the definition of the containers. 
				defined in spec-> containers -> 
  							 - name: Tomcat
    							   image: tomcat: 8.0
  							 - name: database
    							   image: mongoDB


if a single container inside pod fails then whole pod is discarded and new pod is creared as that pod cant be repaired or reconstructed, this is disadvatage of multi conatainer pod .
so , it is recommended that to use Single container



//////    Kubernaetes services 


					////  ***  kubectl    ***   ///
The Kubernetes command-line tool, kubectl, allows you to run commands against Kubernetes clusters. You can use kubectl to deploy applications, inspect and manage cluster resources, and view logs


					////  ***  kind    ***   ///
kind lets you run Kubernetes on your local computer. This tool requires that you have Docker installed and configured.

			
					////  ***   minikube   ***   ///
Like kind, minikube is a tool that lets you run Kubernetes locally. minikube runs a single-node Kubernetes cluster on your personal computer (including Windows, macOS and Linux PCs) so that you can try out Kubernetes, or for daily development work.

	to use local docker images with minikube to deploy using kubernetes , use :   eval $(minikube docker-env)    --- it will get images from local docker registry

																				set imagePullPolicy to Never ,otherwise Kubernetes will try to download the image.

			after that it will create docker specifically for minikube which doesnt contain any of other images which is in local registry

				to pull from local registry use :   minikube image load IMG_NAME 

			after stopping minikube , we can access our local registry of docker that was before minikube wwas started 

					////  ***  kubeadm    ***   ///
You can use the kubeadm tool to create and manage Kubernetes clusters. It performs the actions necessary to get a minimum viable, secure cluster up and running in a user friendly way.


					////  ***  Kops    ***   ///
Kops, short for Kubernetes Operations, is a set of tools for installing, operating, and deleting Kubernetes clusters in the cloud. A rolling upgrade of an older version of Kubernetes to a new version can also be performed. It also manages the cluster add-ons.


					////  ***  kublet    ***   ///
kubelet: the component that runs on all of the machines in your cluster and does things like starting pods and containers.





Replication Controller is one of the key features of Kubernetes, which is responsible for managing the pod lifecycle. It is responsible for making sure that the specified number of pod replicas are running at any point of time. It is used in time when one wants to make sure that the specified number of pod or at least one pod is running. It has the capability to bring up or down the specified no of pod.

/// Volumes

In Kubernetes, a volume can be thought of as a directory which is accessible to the containers in a pod. We have different types of volumes in Kubernetes and the type defines how the volume is created and its content.

The concept of volume was present with the Docker, however the only issue was that the volume was very much limited to a particular pod. As soon as the life of a pod ended, the volume was also lost.

On the other hand, the volumes that are created through Kubernetes is not limited to any container. It supports any or all the containers deployed inside the pod of Kubernetes. A key advantage of Kubernetes volume is, it supports different kind of storage wherein the pod can use multiple of them at the same time.
